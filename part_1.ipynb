{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting up the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# Set OS-independent paths, relative to current directory\n",
        "en_train_path = os.path.join(\"dataset\", \"EN\", \"train\")\n",
        "en_dev_in_path = os.path.join(\"dataset\", \"EN\", \"dev.in\")\n",
        "en_dev_out_path = os.path.join(\"dataset\", \"EN\", \"dev.out\")\n",
        "en_dev_p1_out_path = os.path.join(\"dataset\", \"EN\", \"dev.p1.out\")\n",
        "en_dev_p2_out_path = os.path.join(\"dataset\", \"EN\", \"dev.p2.out\")\n",
        "en_dev_p3_out_path = os.path.join(\"dataset\", \"EN\", \"dev.p3.out\")\n",
        "en_dev_p4_out_path = os.path.join(\"dataset\", \"EN\", \"dev.p4.out\")\n",
        "\n",
        "en_test_in_path = os.path.join(\"Test\", \"EN\", \"test.in\")\n",
        "en_test_out_path = os.path.join(\"Test\", \"EN\", \"test.p4.out\")\n",
        "\n",
        "fr_train_path = os.path.join(\"dataset\", \"FR\", \"train\")\n",
        "fr_dev_in_path = os.path.join(\"dataset\", \"FR\", \"dev.in\")\n",
        "fr_dev_out_path = os.path.join(\"dataset\", \"FR\", \"dev.out\")\n",
        "fr_dev_p1_out_path = os.path.join(\"dataset\", \"FR\", \"dev.p1.out\")\n",
        "fr_dev_p2_out_path = os.path.join(\"dataset\", \"FR\", \"dev.p2.out\")\n",
        "fr_dev_p3_out_path = os.path.join(\"dataset\", \"FR\", \"dev.p3.out\")\n",
        "fr_dev_p4_out_path = os.path.join(\"dataset\", \"FR\", \"dev.p4.out\")\n",
        "\n",
        "fr_test_in_path = os.path.join(\"Test\", \"FR\", \"test.in\")\n",
        "fr_test_out_path = os.path.join(\"Test\", \"FR\", \"test.p4.out\")\n",
        "\n",
        "# Define constant variables\n",
        "N = 7\n",
        "labels = {\"START\": 0,\n",
        "          \"O\": 1,\n",
        "          \"B-positive\": 2,\n",
        "          \"I-positive\": 3,\n",
        "          \"B-neutral\": 4,\n",
        "          \"I-neutral\": 5,\n",
        "          \"B-negative\": 6,\n",
        "          \"I-negative\": 7,\n",
        "          \"END\": 8}\n",
        "labels_list = [\"START\", \"O\", \"B-positive\", \"I-positive\", \"B-neutral\", \"I-neutral\", \"B-negative\", \"I-negative\", \"END\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create labels dictionary and list (for EN)\n",
        "def create_labels_array_dict(filepath):\n",
        "\n",
        "    output_labels_dict = {\"START\": 0}\n",
        "    \n",
        "    output_labels_array = [\"START\"]\n",
        "\n",
        "    counter = 1\n",
        "\n",
        "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
        "        lines = file.readlines()\n",
        "        for line in lines:\n",
        "            if len(line.strip().rsplit(\" \", 1)) == 2: \n",
        "                _, label = line.strip().rsplit(\" \", 1)\n",
        "                \n",
        "                # Reference to check if key exist in dictionary: https://www.geeksforgeeks.org/python-check-whether-given-key-already-exists-in-a-dictionary/\n",
        "                if label not in output_labels_dict.keys():\n",
        "                    output_labels_dict[label] = counter\n",
        "                    output_labels_array.append(label)\n",
        "                    counter += 1\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "    output_labels_dict[\"END\"] = counter\n",
        "    output_labels_array.append(\"END\")\n",
        "\n",
        "    # counter - 1 to replace global variable N. \n",
        "    return output_labels_array, output_labels_dict, counter - 1\n",
        "\n",
        "\n",
        "print(create_labels_array_dict(en_train_path))\n",
        "print(create_labels_array_dict(fr_train_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read training data\n",
        "print(labels)\n",
        "def read_training_data(filepath):\n",
        "    ''' NOTE: This returns results in tuple form, but without start and end. Not sure if anyone needs this function to be in this form, \n",
        "                so I wrote another function called generate_data_tuple_list_with_start_end() which is the same as read_training_data but with\n",
        "                start and end. - Jonah'''\n",
        "\n",
        "    results = []\n",
        "\n",
        "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
        "        lines = file.readlines()\n",
        "        for line in lines:\n",
        "            if len(line.strip().rsplit(\" \", 1)) == 2: # Make sure the line has two elements: word and label\n",
        "                word, label = line.strip().rsplit(\" \", 1)\n",
        "                results.append((word, labels[label]))\n",
        "                \n",
        "            else:\n",
        "                continue\n",
        "    return results\n",
        "\n",
        "print(read_training_data(fr_train_path))\n",
        "\n",
        "# Read dev.in data\n",
        "# There are no labels, just list of words\n",
        "def read_dev_in_data(filepath):\n",
        "    results = []\n",
        "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
        "        lines = file.readlines()\n",
        "        for line in lines:\n",
        "            results.append(line.strip())\n",
        "    return results\n",
        "# print(read_dev_in_data(fr_dev_in_path))\n",
        "\n",
        "\n",
        "# Generate data in tuple form but with (\" \", START_index) and (\" \", END_index)\n",
        "def generate_data_tuple_list_with_start_end(filepath):\n",
        "    results = []\n",
        "\n",
        "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
        "        lines = file.readlines()\n",
        "        for line in lines:\n",
        "            if len(line.strip().rsplit(\" \", 1)) == 2: # Like in read_training_data, to make sure that this line has two elements: word and label\n",
        "                word, label = line.strip().rsplit(\" \", 1)\n",
        "                results.append((word, labels[label]))\n",
        "                \n",
        "            else:\n",
        "                # Enters here if it is the end of the sequence.\n",
        "                results.append((\" \", labels[\"END\"]))\n",
        "                results.append((\" \", labels[\"START\"]))\n",
        "\n",
        "                \n",
        "    return results\n",
        "\n",
        "print(generate_data_tuple_list_with_start_end(fr_train_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate number of each labels, with the keys being the index of the label in labels_list\n",
        "def calculate_number_of_labels(input_data):\n",
        "    return Counter(elem[1] for elem in input_data)\n",
        "print(calculate_number_of_labels(read_training_data(fr_train_path)))\n",
        "\n",
        "# Print out all the words that are unique\n",
        "def get_all_unique_words(input_data):\n",
        "    print(len(set(item[0] for item in input_data)))\n",
        "    return list(set(item[0] for item in input_data))\n",
        "print(get_all_unique_words(read_training_data(fr_train_path)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##################################\n",
        "###### Part 1 Point 1 and 2 ######\n",
        "\n",
        "# For the return value, we follow the matrix format defined in the slides accordingly\n",
        "def calculate_emission_parameters(input_data, all_unique_tokens, k=1.0):\n",
        "    \n",
        "    ''' NOTE: input_data is a list of tuples. '''\n",
        "\n",
        "    # Initialisation for emission_counts\n",
        "    # Final index is for #UNK# tokens\n",
        "    emission_counts = np.zeros((N, len(all_unique_tokens) + 1), dtype=np.longdouble)\n",
        "\n",
        "    # Calculate number of each labels and store in a list\n",
        "    label_counts = np.array(list(val[1] for val in sorted(calculate_number_of_labels(input_data).items())))\n",
        "    print(label_counts)\n",
        "\n",
        "    for token, labels_list_index in input_data:\n",
        "        emission_counts[labels_list_index - 1][all_unique_tokens.index(token)] += 1\n",
        "\n",
        "    # This is for the other case of #UNK# tokens\n",
        "    emission_counts[:, -1] = np.full((1, N), k)[0]\n",
        "\n",
        "\n",
        "    # Initialisation for emission_parameters\n",
        "    emission_parameters = np.empty((N, len(all_unique_tokens) + 1), dtype=np.longdouble)\n",
        "\n",
        "    for index, _ in enumerate(emission_counts):\n",
        "        emission_parameters[index] = emission_counts[index] / (label_counts[index] + k)\n",
        "    \n",
        "    return emission_parameters\n",
        " \n",
        "\n",
        "\n",
        "###### Part 1 Point 1 and 2 ######\n",
        "##################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get tag from word\n",
        "def get_label_from_word(input_word, all_unique_tokens, emission_parameters):\n",
        "    if input_word not in all_unique_tokens:\n",
        "        column_to_consider = emission_parameters[:, -1]\n",
        "    else:\n",
        "        column_to_consider = emission_parameters[:, all_unique_tokens.index(input_word)]\n",
        "\n",
        "    # Randomly choose the index if there is more than one argmax value\n",
        "    x = np.random.choice(np.argwhere(np.isclose(column_to_consider, column_to_consider.max())).flatten()) + 1\n",
        "    return labels_list[x]\n",
        "  \n",
        "# print(get_label_from_word(\"nourriture\", get_all_unique_words(read_training_data(fr_train_path)), calculate_emission_parameters(read_training_data(fr_train_path), get_all_unique_words(read_training_data(fr_train_path)))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def write_prediction_output_to_file(language):\n",
        "    if language == \"EN\":\n",
        "        # Conduct training/supervised learning (M-Step)\n",
        "        train_data = read_training_data(en_train_path)\n",
        "        all_unique_tokens = get_all_unique_words(train_data)\n",
        "        emission_parameters = calculate_emission_parameters(train_data, all_unique_tokens)\n",
        "\n",
        "        # Execute testing/decoding (E-Step)\n",
        "        predicted_results = []\n",
        "        test_data = read_dev_in_data(en_dev_in_path)\n",
        "        for token in test_data:\n",
        "            if token:\n",
        "                predicted_results.append(token + \" \" + get_label_from_word(token, all_unique_tokens, emission_parameters))\n",
        "            else:\n",
        "                predicted_results.append(\"\")\n",
        "        with open(en_dev_p1_out_path, \"w+\", encoding=\"utf-8\") as file:\n",
        "            for line in predicted_results:\n",
        "                file.write(line + \"\\n\")\n",
        "\n",
        "    elif language == \"FR\":\n",
        "        # Conduct training/supervised learning (M-Step)\n",
        "        train_data = read_training_data(fr_train_path)\n",
        "        all_unique_tokens = get_all_unique_words(train_data)\n",
        "        emission_parameters = calculate_emission_parameters(train_data, all_unique_tokens)\n",
        "\n",
        "        # Execute testing/decoding (E-Step)\n",
        "        predicted_results = []\n",
        "        test_data = read_dev_in_data(fr_dev_in_path)\n",
        "        for token in test_data:\n",
        "            if token:\n",
        "                predicted_results.append(token + \" \" + get_label_from_word(token, all_unique_tokens, emission_parameters))\n",
        "            else:\n",
        "                predicted_results.append(\"\")\n",
        "        with open(fr_dev_p1_out_path, \"w+\", encoding=\"utf-8\") as file:\n",
        "            for line in predicted_results:\n",
        "                file.write(line + \"\\n\")\n",
        "                \n",
        "write_prediction_output_to_file(\"FR\")\n",
        "\n",
        "# Temporary store the FR labels, labels_list and N \n",
        "FR_labels_list, FR_labels, FR_N = labels_list, labels, N\n",
        "\n",
        "\n",
        "labels_list, labels, N = create_labels_array_dict(en_train_path)\n",
        "#print(labels_list, labels)\n",
        "write_prediction_output_to_file(\"EN\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#############################\n",
        "####### Part 1 Point 3 ######\n",
        "\n",
        "def read_dev_out_data(filepath):\n",
        "    results = []\n",
        "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
        "        lines = file.readlines()\n",
        "        for line in lines:\n",
        "            results.append(line.strip())\n",
        "    return results\n",
        "\n",
        "\n",
        "\n",
        "####### Part 1 Point 3 ######\n",
        "#############################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "''' NOTE: Use the powershell command in the cell below this cell instead. '''\n",
        "\n",
        "def count_number_of_entities(input_tuple_data, labels_list):\n",
        "    # This is the function for counting entities, that is, when transit from START to B OR I and from O to B OR I and from I to B\n",
        "    # Also need to consider whether there are cases of, for example, going from I-positive to I-neutral, or B-positive to B-neutral, etc.\n",
        "    # By counting the number of transition from O to an entity, we should get the number of entities.\n",
        "\n",
        "    total_count_of_entities = 0; \n",
        "    \n",
        "\n",
        "    for i in range(0, len(input_tuple_data) - 1):\n",
        "        # (len(input_tuple_data) - 1) is due to the accessing of index (i + 1) below. \n",
        "        # So subtract by one in the for loop range to prevent iteration from going out of the index range of input_tuple_data. \n",
        "\n",
        "        # To store the labels in one transition first \n",
        "        prev_label_index = input_tuple_data[i][1]\n",
        "        next_label_index = input_tuple_data[i + 1][1]\n",
        "\n",
        "        # Reference to check if a string contains a substring: https://stackoverflow.com/questions/3437059/does-python-have-a-string-contains-substring-method\n",
        "        if((labels_list[prev_label_index] == \"START\" or labels_list[prev_label_index] == \"O\") \n",
        "           and (\"B-\" in labels_list[next_label_index] or \"I-\" in labels_list[next_label_index])):\n",
        "            # Considers cases where labels transit from START or O to any B- OR I- labels. \n",
        "            total_count_of_entities += 1\n",
        "\n",
        "        elif(\"B-\" in labels_list[prev_label_index] or \"I-\" in labels_list[prev_label_index]):\n",
        "            if(\"B-\" in labels_list[next_label_index]):\n",
        "                # Considers cases like transition from B-positive to B-positive, or B-positive to B-neutral, etc.\n",
        "                # Also considers cases like transition from I-positive to B-positive or B-neutral or B-negative.\n",
        "                total_count_of_entities += 1\n",
        "\n",
        "            elif(\"I-\" in labels_list[next_label_index] and labels_list[prev_label_index][2:] != labels_list[next_label_index][2:]):\n",
        "                # Considers cases like transition from B-positive to I-neutral and I-negative, BUT NOT B-positive to I-positive.\n",
        "                # Also considers cases like transition from I-positive to I-neutral and I-negative, BUT NOT I-positve to I-positive.\n",
        "\n",
        "                # \"labels_list[prev_label_index][2:] != labels_list[next_label_index][2:]\" part of the if conditions is \n",
        "                #   to check that both labels are not both positive and positive, or neutral and neutral, or negative and negative. \n",
        "\n",
        "                total_count_of_entities += 1\n",
        "      \n",
        "\n",
        "    return total_count_of_entities\n",
        "    \n",
        "\n",
        "def compare_data(dev_out_tuple_data, dev_p1_out_tuple_data):\n",
        "    \n",
        "    total_count_of_correct_entities = 0\n",
        "    whole_entity_correct = False\n",
        "\n",
        "    for i in range(1, len(dev_out_tuple_data) - 1):\n",
        "        # Use dev_out range as anything more in dev_p1_out means that the rest in dev_p1_out are wrong?\n",
        "\n",
        "\n",
        "        # To store the labels in transitions \n",
        "        prev_gold_label_index = dev_out_tuple_data[i - 1][1]\n",
        "        current_gold_label_index = dev_out_tuple_data[i][1]\n",
        "        next_gold_label_index = dev_out_tuple_data[i + 1][1]\n",
        "\n",
        "\n",
        "        if(\"B-\" in labels_list[current_gold_label_index]):\n",
        "            # Below if and elif are all checking if the end of the entity has been reached. As long as current label is B-xxxx , it is the start of the entity.\n",
        "\n",
        "            if dev_out_tuple_data[i] == dev_p1_out_tuple_data[i]:\n",
        "               # Boolean turns false when one part of gold entity does not match predicted\n",
        "               whole_entity_correct = True\n",
        "\n",
        "\n",
        "            if(\"B-\" in labels_list[next_gold_label_index]):\n",
        "                # Considers cases like transition from B-positive to B-positive, or B-positive to B-neutral, etc.\n",
        "                \n",
        "\n",
        "                if(whole_entity_correct):\n",
        "                    # Have reached the end of one entity before proceeding to a subsequent entity.\n",
        "                    # Only considering the previous entity (whose end we have reached) without considering the subsequent entity yet.\n",
        "                    # If the previous gold entity had no part that is different from the predicted data, then add to the count of correctly predicted entities.\n",
        "                    \n",
        "                    total_count_of_correct_entities += 1\n",
        "\n",
        "                \n",
        "                # Reset boolean to false, which would be turned to true later if the start of the next gold entity is the same as the predicted \n",
        "                whole_entity_correct = False\n",
        "\n",
        "                \n",
        "\n",
        "            elif(\"I-\" in labels_list[next_gold_label_index] and labels_list[current_gold_label_index][2:] != labels_list[next_gold_label_index][2:]):\n",
        "                # Considers cases like transition from B-positive to I-neutral and I-negative, BUT NOT B-positive to I-positive.\n",
        "  \n",
        "                # \"labels_list[current_gold_label_index][2:] != labels_list[next_gold_label_index][2:]\" part of the if conditions is \n",
        "                #   to check that both labels are not both positive and positive, or neutral and neutral, or negative and negative. \n",
        "\n",
        "                if(whole_entity_correct):\n",
        "                    # Have reached the end of one entity before proceeding to a subsequent entity.\n",
        "                    # Only considering the previous entity (whose end we have reached) without considering the subsequent entity yet.\n",
        "                    # If the previous gold entity had no part that is different from the predicted data, then add to the count of correctly predicted entities.\n",
        "                    \n",
        "                    total_count_of_correct_entities += 1\n",
        "\n",
        "                \n",
        "                # Reset boolean to false, which would be turned to true later if the start of the next gold entity is the same as the predicted \n",
        "                whole_entity_correct = False\n",
        "\n",
        "\n",
        "\n",
        "            elif(labels_list[next_gold_label_index] == \"O\" or labels_list[next_gold_label_index] == \"END\"):\n",
        "                if(whole_entity_correct):\n",
        "                    # Have reached the end of one entity before continuing or ending current sequence.\n",
        "                    # If the previous gold entity had no part that is different from the predicted data, then add to the count of correctly predicted entities.\n",
        "                    # Set boolean to false, which would be turned to true later if the start of the next gold entity is the same as the predicted \n",
        "\n",
        "                    total_count_of_correct_entities += 1\n",
        "\n",
        "                \n",
        "                # Reset boolean to false, which would be turned to true later if the start of the next gold entity is the same as the predicted \n",
        "                whole_entity_correct = False\n",
        "\n",
        "\n",
        "        elif(\"I-\" in labels_list[current_gold_label_index]):\n",
        "            \n",
        "            # Checking if it is still in the same entity\n",
        "            if((\"I-\" in labels_list[prev_gold_label_index] or \"B-\" in labels_list[prev_gold_label_index]) \n",
        "               and labels_list[prev_gold_label_index][2:] == labels_list[current_gold_label_index][2:]):\n",
        "                # Considers cases of transition from B-positive to I-positive, B-neutral to I-neutral and B-negative to I-negative.\n",
        "                # Also considers cases of transition from I-positive to I-positive, I-neutral to  I-neutral, and I-negative to I-negative.\n",
        "\n",
        "                # \"labels_list[prev_gold_label_index][2:] == labels_list[current_gold_label_index][2:]\" part of the if conditions is \n",
        "                #   to check that both labels are both positive and positive, or neutral and neutral, or negative and negative. \n",
        "\n",
        "                # In the middle of an entity.\n",
        "                # If this part of the gold entity is not the same as the predicted, the whole predicted entity is wrongly predicted.\n",
        "                whole_entity_correct = dev_out_tuple_data[i] == dev_p1_out_tuple_data[i]\n",
        "\n",
        "\n",
        "\n",
        "            # Checking if the start of entity has been reached and the start label of the entity is I-xxxxx .\n",
        "            elif((\"I-\" in labels_list[prev_gold_label_index] or \"B-\" in labels_list[prev_gold_label_index]) and labels_list[prev_gold_label_index][2:] != labels_list[current_gold_label_index][2:]):\n",
        "                # Considers cases like transition from B-positive to I-neutral and I-negative, BUT NOT B-positive to I-positive.\n",
        "                # Also considers cases like transition from I-positive to I-neutral and I-negative, BUT NOT I-positve to I-positive.\n",
        "                # if dev_out_tuple_data[i] == dev_p1_out_tuple_data[i], whole_entity_correct becomes True\n",
        "                whole_entity_correct = dev_out_tuple_data[i] == dev_p1_out_tuple_data[i]\n",
        "\n",
        "            elif labels_list[prev_gold_label_index] == \"O\":\n",
        "                whole_entity_correct = dev_out_tuple_data[i] == dev_p1_out_tuple_data[i]\n",
        "                \n",
        "            \n",
        "            # Checking if end of entity. Use if and not elif as this block must still be checked even if the above if and elif were true.\n",
        "            if(\"I-\" in labels_list[next_gold_label_index] and labels_list[current_gold_label_index][2:] != labels_list[next_gold_label_index][2:]):\n",
        "                # Considers cases like transition from I-positive to I-neutral and I-negative, BUT NOT I-positve to I-positive.\n",
        "\n",
        "                # \"labels_list[current_gold_label_index][2:] != labels_list[next_gold_label_index][2:]\" part of the if conditions is \n",
        "                #   to check that both labels are not both positive and positive, or neutral and neutral, or negative and negative. \n",
        "\n",
        "                if whole_entity_correct:\n",
        "                    # Have reached the end of one entity before proceeding to a subsequent entity.\n",
        "                    # Only considering the previous entity (whose end we have reached) without considering the subsequent entity yet.\n",
        "                    # If the previous gold entity had no part that is different from the predicted data, then add to the count of correctly predicted entities.\n",
        "                    \n",
        "                    total_count_of_correct_entities += 1\n",
        "\n",
        "                # Reset boolean to false, which would be turned to true later if the start of the next gold entity is the same as the predicted \n",
        "                whole_entity_correct = False\n",
        "\n",
        "\n",
        "            elif(\"B-\" in labels_list[next_gold_label_index] or labels_list[next_gold_label_index] == \"O\" or labels_list[next_gold_label_index] == \"END\"):\n",
        "                if whole_entity_correct:\n",
        "                    # Have reached the end of one entity before continuing or ending current sequence.\n",
        "                    # If the previous gold entity had no part that is different from the predicted data, then add to the count of correctly predicted entities.\n",
        "                    # Set boolean to false, which would be turned to true later if the start of the next gold entity is the same as the predicted \n",
        "\n",
        "                    total_count_of_correct_entities += 1\n",
        "\n",
        "                \n",
        "                # Reset boolean to false, which would be turned to true later if the start of the next gold entity is the same as the predicted \n",
        "                whole_entity_correct = False\n",
        "\n",
        "                \n",
        "    return total_count_of_correct_entities\n",
        "\n",
        "def precision_or_recall_calculation(correct_count, total_count):\n",
        "    return correct_count / total_count\n",
        "\n",
        "def f_score_calculation(precision, recall):\n",
        "    return 2 / ( (1/precision) + (1/recall) )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#######################\n",
        "####### FR Data #######\n",
        "\n",
        "labels_list, labels, N = FR_labels_list, FR_labels, FR_N\n",
        "fr_dev_out_storage = generate_data_tuple_list_with_start_end(fr_dev_out_path)\n",
        "fr_dev_p1_out_storage = generate_data_tuple_list_with_start_end(fr_dev_p1_out_path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''COUNTING PREDICTED'''\n",
        "total_count_of_predicted_entities = count_number_of_entities(fr_dev_p1_out_storage, labels_list)\n",
        "\n",
        "'''COUNTING GOLD'''\n",
        "total_count_of_gold_entities = count_number_of_entities(fr_dev_out_storage, labels_list)\n",
        "\n",
        "correct_count = compare_data(fr_dev_out_storage, fr_dev_p1_out_storage)\n",
        "precision = precision_or_recall_calculation(correct_count, total_count_of_predicted_entities)\n",
        "recall = precision_or_recall_calculation(correct_count, total_count_of_gold_entities)\n",
        "f_score = f_score_calculation(precision, recall)\n",
        "\n",
        "\n",
        "print(\"Total count of FR predicted entities: \", total_count_of_predicted_entities)\n",
        "print(\"Total count of FR gold entities: \", total_count_of_gold_entities)\n",
        "print(\"Total number of correctly predicted entities: \", correct_count)\n",
        "print()\n",
        "print(\"FR Values:\")\n",
        "print(\"Precision: \", precision)\n",
        "print(\"Recall: \", recall)\n",
        "print(\"FR F_Score: \", f_score)\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n\\n\\n\\n\")\n",
        "\n",
        "\n",
        "\n",
        "#######################\n",
        "####### EN Data #######\n",
        "\n",
        "labels_list, labels, N = create_labels_array_dict(en_train_path)\n",
        "en_dev_out_storage = generate_data_tuple_list_with_start_end(en_dev_out_path)\n",
        "en_dev_p1_out_storage = generate_data_tuple_list_with_start_end(en_dev_p1_out_path)\n",
        "\n",
        "'''COUNTING PREDICTED'''\n",
        "total_count_of_predicted_entities = count_number_of_entities(en_dev_p1_out_storage, labels_list)\n",
        "\n",
        "'''COUNTING GOLD'''\n",
        "total_count_of_gold_entities = count_number_of_entities(en_dev_out_storage, labels_list)\n",
        "\n",
        "correct_count = compare_data(fr_dev_out_storage, fr_dev_p1_out_storage)\n",
        "precision = precision_or_recall_calculation(correct_count, total_count_of_predicted_entities)\n",
        "recall = precision_or_recall_calculation(correct_count, total_count_of_gold_entities)\n",
        "f_score = f_score_calculation(precision, recall)\n",
        "\n",
        "print(\"Total count of EN predicted entities: \", total_count_of_predicted_entities)\n",
        "print(\"Total count of EN gold entities: \", total_count_of_gold_entities)\n",
        "print(\"Total number of correctly predicted entities: \", correct_count)\n",
        "print()\n",
        "print(\"EN Values:\")\n",
        "print(\"Precision: \", precision)\n",
        "print(\"Recall: \", recall)\n",
        "print(\"EN F_Score: \", f_score)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "''' NOTE: Use the powershell command in the cell below this cell instead. '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "#Entity in gold data: 238\n",
            "#Entity in prediction: 1114\n",
            "\n",
            "#Correct Entity : 186\n",
            "Entity  precision: 0.1670\n",
            "Entity  recall: 0.7815\n",
            "Entity  F: 0.2751\n",
            "\n",
            "#Correct Sentiment : 79\n",
            "Sentiment  precision: 0.0709\n",
            "Sentiment  recall: 0.3319\n",
            "Sentiment  F: 0.1169\n",
            "\n",
            "#Entity in gold data: 802\n",
            "#Entity in prediction: 1081\n",
            "\n",
            "#Correct Entity : 587\n",
            "Entity  precision: 0.5430\n",
            "Entity  recall: 0.7319\n",
            "Entity  F: 0.6235\n",
            "\n",
            "#Correct Sentiment : 448\n",
            "Sentiment  precision: 0.4144\n",
            "Sentiment  recall: 0.5586\n",
            "Sentiment  F: 0.4758\n"
          ]
        }
      ],
      "source": [
        "!python .\\dataset\\FR\\evalResult.py .\\dataset\\FR\\dev.out .\\dataset\\FR\\dev.p1.out\n",
        "\n",
        "!python .\\dataset\\EN\\evalResult.py .\\dataset\\EN\\dev.out .\\dataset\\EN\\dev.p1.out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#############################\n",
        "####### Part 2 Point 1 ######\n",
        "\n",
        "def count_transition_from_u_to_v(input_tuple_data, index_of_u_label, index_of_v_label):\n",
        "\n",
        "    # This is the function for Count(y_(i-1), y_i), that is, Count(u, v).\n",
        "\n",
        "    total_count_of_such_transition = 0; \n",
        "\n",
        "    for i in range(0, len(input_tuple_data) - 1):\n",
        "        # (len(input_tuple_data) - 1) is due to the accessing of index (i + 1) below. \n",
        "        # So subtract by one in the for loop range to prevent iteration from going out of the index range of input_tuple_data. \n",
        "\n",
        "        # To store the labels in one transition first \n",
        "        prev_label_index = input_tuple_data[i][1]\n",
        "        next_label_index = input_tuple_data[i + 1][1]\n",
        "\n",
        "        if(prev_label_index == index_of_u_label and next_label_index == index_of_v_label):\n",
        "            total_count_of_such_transition += 1\n",
        "\n",
        "    return total_count_of_such_transition\n",
        "\n",
        "\n",
        "\n",
        "def maximum_likelihood_estimation(transition_from_u_to_v_count, total_count_of_u):\n",
        "    # This is the MLE function, which is q(y_i | y_(i-1)), that is, q(v | u).\n",
        "\n",
        "    return transition_from_u_to_v_count / total_count_of_u\n",
        "\n",
        "\n",
        "\n",
        "''' NOTE: Using generate_data_tuple_list_with_start_end() to generate tuple data with start and end included.'''\n",
        "#######################\n",
        "####### FR Data #######\n",
        "print(\"FR\")\n",
        "print()\n",
        "\n",
        "labels_list, labels, N = FR_labels_list, FR_labels, FR_N\n",
        "input_tuple_data = generate_data_tuple_list_with_start_end(fr_train_path) # Note the function used.\n",
        "labels_count = calculate_number_of_labels(input_tuple_data)\n",
        "\n",
        "\n",
        "\n",
        "for u in range(0, len(labels_list) - 1):\n",
        "    # From START to y_n. This is the index for u.\n",
        "\n",
        "    for v in range(1, len(labels_list)):\n",
        "        # From y_1 to END. This is the index for v.\n",
        "\n",
        "        val_of_count_transition_from_u_to_v = count_transition_from_u_to_v(input_tuple_data, u, v)\n",
        "\n",
        "        print(\"Count(\" + labels_list[u] + \", \" + labels_list[v] + \"): \", val_of_count_transition_from_u_to_v)\n",
        "        print(\"Maximum likelihood estimation is:\", maximum_likelihood_estimation(val_of_count_transition_from_u_to_v, labels_count[u]))\n",
        "        print()\n",
        "       \n",
        "\n",
        "#######################\n",
        "####### EN Data #######\n",
        "print()\n",
        "print()\n",
        "print(\"EN\")\n",
        "print()\n",
        "\n",
        "labels_list, labels, N = create_labels_array_dict(en_train_path)\n",
        "input_tuple_data = generate_data_tuple_list_with_start_end(en_train_path) # Note the function used.\n",
        "labels_count = calculate_number_of_labels(input_tuple_data)\n",
        "\n",
        "\n",
        "for u in range(0, len(labels_list) - 1):\n",
        "    # From START to y_n. This is the index for u.\n",
        "\n",
        "    for v in range(1, len(labels_list)):\n",
        "        # From y_1 to END. This is the index for v.\n",
        "\n",
        "        val_of_count_transition_from_u_to_v = count_transition_from_u_to_v(input_tuple_data, u, v)\n",
        "\n",
        "        print(\"Count(\" + labels_list[u] + \", \" + labels_list[v] + \"): \", val_of_count_transition_from_u_to_v)\n",
        "        print(\"Maximum likelihood estimation is:\", maximum_likelihood_estimation(val_of_count_transition_from_u_to_v, labels_count[u]))\n",
        "        print()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#############################\n",
        "####### Part 2 Point 2 ######\n",
        "\n",
        "def get_emission_from_words(word, unique_words, emission_params):\n",
        "    if word not in unique_words:\n",
        "        b = emission_params[:, -1]\n",
        "    else:\n",
        "        b = emission_params[:, unique_words.index(word)]\n",
        "    return np.reshape(np.pad(b, 1), (-1, 1))\n",
        "\n",
        "\n",
        "def get_parent_state(probs):\n",
        "    parent_indices = []\n",
        "    for i in range(probs.shape[1]):\n",
        "        column = probs[1:-1, i]\n",
        "        max_value = column.max(axis=0)\n",
        "        max_value_indices = np.argwhere(column == max_value).flatten()\n",
        "        chosen_index = np.random.choice(max_value_indices) + 1\n",
        "        parent_indices.append(chosen_index)\n",
        "    return parent_indices\n",
        "\n",
        "\n",
        "def viterbi(transition, emission, tokens, labels, data):\n",
        "    # Initial step\n",
        "    log_transition = np.log(transition)\n",
        "    pi = [np.log(np.zeros([log_transition.shape[0], 1]))]\n",
        "    pi[0][0] = 0\n",
        "    parents = []\n",
        "    time_step = 0\n",
        "    results = []\n",
        "    \n",
        "    for word in data:\n",
        "        if not word: \n",
        "            # End of sentence, perform backtracking\n",
        "            probs = pi[time_step] + log_transition[:,-1:]\n",
        "            output = get_parent_state(probs)\n",
        "            while time_step > 1:\n",
        "                time_step -= 1\n",
        "                output.insert(0, parents[time_step][output[0]])\n",
        "            for i in output:\n",
        "                results.append(labels[i])\n",
        "            results.append('')\n",
        "            # Reset variables\n",
        "            pi = [np.log(np.zeros([log_transition.shape[0], 1]))]\n",
        "            pi[0][0] = 0\n",
        "            parents = []\n",
        "            time_step = 0\n",
        "        else:\n",
        "            # Calculate the probability of the current observation\n",
        "            log_emissions = np.log(get_emission_from_words(word, tokens, emission))\n",
        "            probs = np.matmul(pi[time_step], np.transpose(np.ones(log_emissions.shape))) \\\n",
        "                    + np.matmul(np.ones(log_emissions.shape), np.transpose(log_emissions)) \\\n",
        "                    + log_transition\n",
        "            pi.append(np.reshape(probs.max(axis=0), (-1, 1)))\n",
        "            parents.append(get_parent_state(probs))\n",
        "            time_step += 1\n",
        "    \n",
        "    return results\n",
        "\n",
        "def calculate_transition_parameters(data):\n",
        "    transition_counts = np.zeros([N+2, N+2])\n",
        "    priori_counts = np.zeros([N+2, 1])\n",
        "    prev = 0\n",
        "    for pair in data:\n",
        "        curr = pair[1]\n",
        "        priori_counts[prev] += 1\n",
        "        transition_counts[prev, curr] += 1\n",
        "        prev = curr\n",
        "    transition = transition_counts / priori_counts\n",
        "    transition[-1, 0] = 0 \n",
        "    \n",
        "    return transition\n",
        "\n",
        "labels_list, labels, N = create_labels_array_dict(fr_train_path)\n",
        "input_data_start_end = generate_data_tuple_list_with_start_end(fr_train_path)\n",
        "input_data = read_training_data(fr_train_path)\n",
        "all_unique_words = get_all_unique_words(input_data)\n",
        "transition_params = calculate_transition_parameters(input_data_start_end)\n",
        "emission_params = calculate_emission_parameters(input_data, all_unique_words)\n",
        "test_data = read_dev_in_data(fr_dev_in_path)\n",
        "\n",
        "predicted_results = viterbi(transition_params, emission_params, all_unique_words, labels_list, test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [],
      "source": [
        "def write_viterbi_output_to_file(language):\n",
        "    if language == \"EN\":\n",
        "        labels_list, labels, N = create_labels_array_dict(en_train_path)\n",
        "        input_data = read_training_data(en_train_path)\n",
        "        train_data_w_start_end = generate_data_tuple_list_with_start_end(en_train_path)\n",
        "        test_data = read_dev_in_data(en_dev_in_path)\n",
        "        output_path = en_dev_p2_out_path\n",
        "\n",
        "    elif language == \"FR\":\n",
        "        labels_list, labels, N = create_labels_array_dict(fr_train_path)\n",
        "        input_data = read_training_data(fr_train_path)\n",
        "        train_data_w_start_end = generate_data_tuple_list_with_start_end(fr_train_path)\n",
        "        test_data = read_dev_in_data(fr_dev_in_path)\n",
        "        output_path = fr_dev_p2_out_path\n",
        "\n",
        "    # Conduct training/supervised learning (M-Step)\n",
        "    all_unique_words = get_all_unique_words(input_data)\n",
        "    emission_parameters = calculate_emission_parameters(input_data, all_unique_words)\n",
        "    transition_parameters = calculate_transition_parameters(train_data_w_start_end)\n",
        "    \n",
        "    \n",
        "    # Execute testing/decoding with Viterbi Algorithm (E-Step)\n",
        "    predicted_results = viterbi(transition_parameters, emission_parameters, all_unique_words, labels_list,  test_data)\n",
        "    with open(output_path, \"w+\", encoding=\"utf-8\") as file:\n",
        "        for i in range(len(test_data)):\n",
        "            if test_data[i] and predicted_results[i]:\n",
        "                file.write(\"{} {}\\n\".format(test_data[i], predicted_results[i]))\n",
        "            else:\n",
        "                file.write(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels_list, labels, N = create_labels_array_dict(fr_train_path)\n",
        "\n",
        "write_viterbi_output_to_file(\"FR\")\n",
        "\n",
        "# Temporary store the FR labels, labels_list and N \n",
        "FR_labels_list, FR_labels, FR_N = labels_list, labels, N\n",
        "\n",
        "\n",
        "labels_list, labels, N = create_labels_array_dict(en_train_path)\n",
        "#print(labels_list, labels)\n",
        "write_viterbi_output_to_file(\"EN\")\n",
        "\n",
        "# Temporary store the FR labels, labels_list and N \n",
        "EN_labels_list, EN_labels, EN_N = labels_list, labels, N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "#Entity in gold data: 238\n",
            "#Entity in prediction: 456\n",
            "\n",
            "#Correct Entity : 136\n",
            "Entity  precision: 0.2982\n",
            "Entity  recall: 0.5714\n",
            "Entity  F: 0.3919\n",
            "\n",
            "#Correct Sentiment : 76\n",
            "Sentiment  precision: 0.1667\n",
            "Sentiment  recall: 0.3193\n",
            "Sentiment  F: 0.2190\n",
            "\n",
            "#Entity in gold data: 802\n",
            "#Entity in prediction: 859\n",
            "\n",
            "#Correct Entity : 543\n",
            "Entity  precision: 0.6321\n",
            "Entity  recall: 0.6771\n",
            "Entity  F: 0.6538\n",
            "\n",
            "#Correct Sentiment : 444\n",
            "Sentiment  precision: 0.5169\n",
            "Sentiment  recall: 0.5536\n",
            "Sentiment  F: 0.5346\n"
          ]
        }
      ],
      "source": [
        "!python .\\dataset\\FR\\evalResult.py .\\dataset\\FR\\dev.out .\\dataset\\FR\\dev.p2.out\n",
        "\n",
        "!python .\\dataset\\EN\\evalResult.py .\\dataset\\EN\\dev.out .\\dataset\\EN\\dev.p2.out"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_double_transition_parameters(data):\n",
        "    transition_counts = np.zeros([N+2, N+2, N+2])\n",
        "    priori_counts = np.zeros([N+2, N+2])\n",
        "\n",
        "    prev2 = None\n",
        "    prev = None\n",
        "    \n",
        "    for i in range(len(data)):\n",
        "        # input_data[i] -> ('Ã©coute', 1)\n",
        "        sticky = data[i]\n",
        "        curr = sticky[1]\n",
        "        priori_counts[prev2, prev] += 1\n",
        "        transition_counts[prev2, prev, curr] += 1\n",
        "        \n",
        "        prev2 = prev\n",
        "        prev = curr\n",
        "\n",
        "    for state1 in transition_counts:\n",
        "        for state2 in state1:\n",
        "            state2[0] = 0\n",
        "            state2[-1] = 0\n",
        "\n",
        "    # print(priori_counts)\n",
        "    transition = transition_counts / priori_counts\n",
        "    transition[np.isnan(transition)] =0\n",
        "    return transition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels_list, labels, N = create_labels_array_dict(fr_train_path)\n",
        "\n",
        "input_data_start_end = generate_data_tuple_list_with_start_end(fr_train_path)\n",
        "input_data = read_training_data(fr_train_path)\n",
        "all_unique_words = get_all_unique_words(input_data)\n",
        "transition_params = calculate_double_transition_parameters(input_data)\n",
        "print(transition_params.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def second_order_get_parent_state(probs):\n",
        "    # collect indices of elements from list of probabilities that is max probabilities.\n",
        "    choice_2 = [np.random.choice(np.argwhere(probs[1:-1, i,j] == probs[1:-1, i,j].max(axis=0)).flatten()) + 1 for i in range(probs.shape[1]) for j in range(probs.shape[0]) ]\n",
        "    \n",
        "    split_arr = np.array_split(choice_2, probs.shape[1])\n",
        "    result_lst = []\n",
        "    for sub_arr in split_arr:\n",
        "        unique, counts = np.unique(sub_arr, return_counts=True)\n",
        "        max_freq_idx = np.argmax(counts)\n",
        "        most_common = unique[max_freq_idx]\n",
        "        result_lst.append(most_common)\n",
        "\n",
        "    return result_lst\n",
        "\n",
        "def get_max_index_from_list(choice):\n",
        "    # Same as second_order_get_parent_state, but for a single list.\n",
        "    return [np.bincount(choice).argmax()]\n",
        "\n",
        "\n",
        "def second_order_viterbi_log(transition, emission, tokens, labels, data):\n",
        "    log_transition = np.log(transition)\n",
        "    # initialisation\n",
        "    time_step = 0\n",
        "    pi = [np.log(np.zeros([log_transition.shape[0], log_transition.shape[1], N+2]))]\n",
        "    pi[0][0][0] = 0\n",
        "    parents = []\n",
        "    results = []\n",
        "\n",
        "    for word in data:\n",
        "\n",
        "        if len(word)!=0: \n",
        "            # propagation\n",
        "            log_emissions = np.log(get_emission_from_words(word, tokens, emission))\n",
        "            k = np.arange(pi[time_step].shape[0]).reshape(pi[time_step].shape[1], 1)\n",
        "\n",
        "            probs = np.matmul(k, np.transpose(np.ones(log_emissions.shape))) \\\n",
        "                    + np.matmul(np.ones(log_emissions.shape), np.transpose(log_emissions)) \\\n",
        "                    + log_transition\n",
        "            pi.append(np.reshape(probs.max(axis=0), (log_transition.shape[0],log_transition.shape[1])))\n",
        "            parents.append(second_order_get_parent_state(probs))\n",
        "            time_step += 1\n",
        "        else: \n",
        "            \n",
        "            probs = pi[time_step] + log_transition[:,-1:,-1:]\n",
        "\n",
        "            # backtracking \n",
        "            output = second_order_get_parent_state(probs)\n",
        "            output = get_max_index_from_list(output)\n",
        "\n",
        "            while time_step > 1: \n",
        "                time_step -= 1\n",
        "                output.insert(0, parents[time_step][output[0]])\n",
        "\n",
        "\n",
        "            for i in output:\n",
        "                results.append(labels[i])\n",
        "            # results.append(labels_list[i]) for i in output)\n",
        "            results.append('')\n",
        "\n",
        "            # Reset inits\n",
        "            time_step = 0\n",
        "            pi[0][0][0] = 0\n",
        "            parents = []\n",
        "    \n",
        "    return results\n",
        "\n",
        "labels_list, labels, N = create_labels_array_dict(fr_train_path)\n",
        "input_data_start_end = generate_data_tuple_list_with_start_end(fr_train_path)\n",
        "input_data = read_training_data(fr_train_path)\n",
        "all_unique_words = get_all_unique_words(input_data)\n",
        "transition_params = calculate_double_transition_parameters(input_data_start_end)\n",
        "emission_params = calculate_emission_parameters(input_data, all_unique_words)\n",
        "test_data = read_dev_in_data(fr_dev_in_path)\n",
        "\n",
        "predicted_results = second_order_viterbi_log(transition_params, emission_params, all_unique_words, labels_list, test_data)\n",
        "print(predicted_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "def write_viterbi_output_to_file3(language):\n",
        "    if language == \"EN\":\n",
        "        labels_list, labels, N = create_labels_array_dict(en_train_path)\n",
        "        input_data = read_training_data(en_train_path)\n",
        "        train_data_w_start_end = generate_data_tuple_list_with_start_end(en_train_path)\n",
        "        test_data = read_dev_in_data(en_dev_in_path)\n",
        "        output_path = en_dev_p3_out_path\n",
        "\n",
        "    elif language == \"FR\":\n",
        "        labels_list, labels, N = create_labels_array_dict(fr_train_path)\n",
        "        input_data = read_training_data(fr_train_path)\n",
        "        train_data_w_start_end = generate_data_tuple_list_with_start_end(fr_train_path)\n",
        "        test_data = read_dev_in_data(fr_dev_in_path)\n",
        "        output_path = fr_dev_p3_out_path\n",
        "\n",
        "    # Conduct training/supervised learning (M-Step)\n",
        "    all_unique_words = get_all_unique_words(input_data)\n",
        "    emission_parameters = calculate_emission_parameters(input_data, all_unique_words)\n",
        "    transition_parameters = calculate_double_transition_parameters(train_data_w_start_end)\n",
        "\n",
        "    # Execute testing/decoding with Viterbi Algorithm (E-Step)\n",
        "    predicted_results = second_order_viterbi_log(transition_parameters, emission_parameters, all_unique_words, test_data)\n",
        "    with open(output_path, \"w+\", encoding=\"utf-8\") as file:\n",
        "        for i in range(len(predicted_results)):\n",
        "            if test_data[i] and predicted_results[i]:\n",
        "                file.write(\"{} {}\\n\".format(test_data[i], predicted_results[i]))\n",
        "            else:\n",
        "                file.write(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Temporary store the FR labels, labels_list and N \n",
        "labels_list, labels, N = create_labels_array_dict(fr_train_path)\n",
        "FR_labels_list, FR_labels, FR_N = labels_list, labels, N\n",
        "write_viterbi_output_to_file3(\"FR\")\n",
        "\n",
        "# Temporary store the FR labels, labels_list and N \n",
        "labels_list, labels, N = create_labels_array_dict(en_train_path)\n",
        "EN_labels_list, EN_labels, EN_N = labels_list, labels, N\n",
        "#print(labels_list, labels)\n",
        "write_viterbi_output_to_file3(\"EN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "#Entity in gold data: 238\n",
            "#Entity in prediction: 1100\n",
            "\n",
            "#Correct Entity : 62\n",
            "Entity  precision: 0.0564\n",
            "Entity  recall: 0.2605\n",
            "Entity  F: 0.0927\n",
            "\n",
            "#Correct Sentiment : 21\n",
            "Sentiment  precision: 0.0191\n",
            "Sentiment  recall: 0.0882\n",
            "Sentiment  F: 0.0314\n",
            "\n",
            "#Entity in gold data: 802\n",
            "#Entity in prediction: 680\n",
            "\n",
            "#Correct Entity : 281\n",
            "Entity  precision: 0.4132\n",
            "Entity  recall: 0.3504\n",
            "Entity  F: 0.3792\n",
            "\n",
            "#Correct Sentiment : 50\n",
            "Sentiment  precision: 0.0735\n",
            "Sentiment  recall: 0.0623\n",
            "Sentiment  F: 0.0675\n"
          ]
        }
      ],
      "source": [
        "!python .\\dataset\\FR\\evalResult.py .\\dataset\\FR\\dev.out .\\dataset\\FR\\dev.p3.out\n",
        "\n",
        "!python .\\dataset\\EN\\evalResult.py .\\dataset\\EN\\dev.out .\\dataset\\EN\\dev.p3.out"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "powershell"
        }
      },
      "source": [
        "----\n",
        "# Part 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_unique_words_for_each_label(input_tuple_data, labels_list):\n",
        "    dict_of_count_of_words_in_each_label = {}\n",
        "    dict_of_total_count_unique_words = {}\n",
        "\n",
        "    # Initialisation by setting labels as keys of dictionary, and their values are also dictionaries using unique words as keys.\n",
        "    for i in range(1, len(labels_list) - 1):\n",
        "        # Exclude START and END\n",
        "        dict_of_count_of_words_in_each_label[i] = {}\n",
        "\n",
        "    \n",
        "    for tuple in input_tuple_data:\n",
        "\n",
        "        # Using \"d[key] = d.get(key, 0) + 1\" to set a default value to 0 if key not found in the first place. Reference: https://stackoverflow.com/questions/1602934/check-if-a-given-key-already-exists-in-a-dictionary\n",
        "        dict_of_count_of_words_in_each_label[tuple[1]][tuple[0].lower()] = dict_of_count_of_words_in_each_label[tuple[1]].get(tuple[0].lower(), 0) + 1\n",
        "\n",
        "        dict_of_total_count_unique_words[tuple[0].lower()] = dict_of_total_count_unique_words.get(tuple[0].lower(), 0) + 1\n",
        "\n",
        "\n",
        "    return dict_of_count_of_words_in_each_label, dict_of_total_count_unique_words\n",
        "\n",
        "\n",
        "\n",
        "def probabilities_of_words_in_each_label(dict_of_count_of_words_in_each_label, dict_of_total_count_unique_words):\n",
        "    dict_of_words_prob_in_each_label = {}\n",
        "\n",
        "    # Initialisation by setting labels as keys of dictionary, and their values are also dictionaries.\n",
        "    for i in range(1, len(labels_list) - 1):\n",
        "        # Exclude START and END\n",
        "        dict_of_words_prob_in_each_label[i] = {}\n",
        "\n",
        "    for label_index_key in dict_of_count_of_words_in_each_label:\n",
        "        for unique_word_key in dict_of_count_of_words_in_each_label[label_index_key]:\n",
        "            dict_of_words_prob_in_each_label[label_index_key][unique_word_key] = dict_of_count_of_words_in_each_label[label_index_key][unique_word_key] / (dict_of_total_count_unique_words[unique_word_key]) \n",
        "\n",
        "    return dict_of_words_prob_in_each_label\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def predict_word_sentiment(word, dict_of_words_prob_in_each_label, labels_list, unique_words_list):\n",
        "\n",
        "    current_max_probability = 0\n",
        "    current_most_probable_label_index = 1\n",
        "    \n",
        "    word_lowercase = word.lower()\n",
        "\n",
        "    for label_index_key in dict_of_words_prob_in_each_label:\n",
        "        # Exclude START and END labels\n",
        "        if word_lowercase in dict_of_words_prob_in_each_label[label_index_key]:\n",
        "\n",
        "            if dict_of_words_prob_in_each_label[label_index_key][word_lowercase] > current_max_probability:\n",
        "                current_max_probability = dict_of_words_prob_in_each_label[label_index_key][word_lowercase]\n",
        "                current_most_probable_label_index = label_index_key\n",
        "\n",
        "        \n",
        "\n",
        "    if current_max_probability == 0:\n",
        "        missing_letter_cost = 10             # If either word has a missing letter, continue to add a small value to the \"distance\" between the words. \n",
        "\n",
        "        min_unicode_diff = 1000000\n",
        "        closest_word = \"\"\n",
        "\n",
        "        # Use of .maketrans() to remove accented characters. Reference: https://stackoverflow.com/questions/41004941/python-replace-french-letters-with-english\n",
        "        translation_table = str.maketrans(\"Ã©Ã Ã¨Ã¹Ã¢ÃªÃ®Ã´Ã»Ã§\", \"eaeuaeiouc\")\n",
        "        # Use of .translate() to remove accented characters. Reference: https://stackoverflow.com/questions/41004941/python-replace-french-letters-with-english\n",
        "        translated_word = word.translate(translation_table)\n",
        "        translated_word = translated_word.lower()\n",
        "\n",
        "        for unique_word in unique_words_list:\n",
        "            current_unicode_diff = 0\n",
        "\n",
        "            if len(unique_word) < len(word):\n",
        "                smaller_length = len(unique_word)\n",
        "            else:\n",
        "                smaller_length = len(word)\n",
        "\n",
        "            # Use of .translate() to remove accented characters. Reference: https://stackoverflow.com/questions/41004941/python-replace-french-letters-with-english\n",
        "            translated_unique_word = unique_word.translate(translation_table)\n",
        "            \n",
        "            for i in range(0, smaller_length - 1):\n",
        "                current_unicode_diff += pow((ord(translated_word[i]) - ord(translated_unique_word[i])), 2)\n",
        "\n",
        "            current_unicode_diff += abs(len(word) - len(unique_word)) * missing_letter_cost\n",
        "\n",
        "            if current_unicode_diff < min_unicode_diff:\n",
        "                min_unicode_diff = current_unicode_diff\n",
        "                closest_word = unique_word\n",
        "\n",
        "        for label_index_key in dict_of_words_prob_in_each_label:\n",
        "            if closest_word in dict_of_words_prob_in_each_label[label_index_key] and dict_of_words_prob_in_each_label[label_index_key][closest_word] > current_max_probability:\n",
        "                current_max_probability = dict_of_words_prob_in_each_label[label_index_key][closest_word]\n",
        "                current_most_probable_label_index = label_index_key\n",
        "\n",
        "        \n",
        "    return labels_list[current_most_probable_label_index]\n",
        "\n",
        "def write_prediction_output_to_file_part4(language):\n",
        "\n",
        "    if language == \"EN\":\n",
        "        # Conduct training/supervised learning (M-Step)\n",
        "        labels_list, labels, N = create_labels_array_dict(en_train_path)\n",
        "        input_tuple_data = read_training_data(en_train_path)\n",
        "        labels_count = calculate_number_of_labels(input_tuple_data)\n",
        "        unique_words_list = get_all_unique_words(input_tuple_data)\n",
        "\n",
        "        dict_of_count_of_words_in_each_label, dict_of_total_count_unique_words = count_unique_words_for_each_label(input_tuple_data, labels_list)\n",
        "        dict_of_words_prob_in_each_label = probabilities_of_words_in_each_label(dict_of_count_of_words_in_each_label, dict_of_total_count_unique_words)\n",
        "        \n",
        "\n",
        "        # Execute testing/decoding (E-Step)\n",
        "        predicted_results = []\n",
        "        test_data = read_dev_in_data(en_dev_in_path)\n",
        "\n",
        "        for token in test_data:\n",
        "            if token:\n",
        "                predicted_results.append(token + \" \" + predict_word_sentiment(token, dict_of_words_prob_in_each_label, labels_list, unique_words_list))\n",
        "            else:\n",
        "                predicted_results.append(\"\")\n",
        "        with open(en_dev_p4_out_path, \"w+\", encoding=\"utf-8\") as file:\n",
        "            for line in predicted_results:\n",
        "                file.write(line + \"\\n\")\n",
        "\n",
        "    elif language == \"FR\":\n",
        "        # Conduct training/supervised learning (M-Step)\n",
        "        labels_list, labels, N = FR_labels_list, FR_labels, FR_N\n",
        "        input_tuple_data = read_training_data(fr_train_path)\n",
        "        labels_count = calculate_number_of_labels(input_tuple_data)\n",
        "        unique_words_list = get_all_unique_words(input_tuple_data)\n",
        "\n",
        "\n",
        "        dict_of_count_of_words_in_each_label, dict_of_total_count_unique_words = count_unique_words_for_each_label(input_tuple_data, labels_list)\n",
        "        dict_of_words_prob_in_each_label = probabilities_of_words_in_each_label(dict_of_count_of_words_in_each_label, dict_of_total_count_unique_words)\n",
        "        \n",
        "\n",
        "        # Execute testing/decoding (E-Step)\n",
        "        predicted_results = []\n",
        "        test_data = read_dev_in_data(fr_dev_in_path)\n",
        "\n",
        "        for token in test_data:\n",
        "            if token:\n",
        "                predicted_results.append(token + \" \" + predict_word_sentiment(token, dict_of_words_prob_in_each_label, labels_list, unique_words_list))\n",
        "            else:\n",
        "                predicted_results.append(\"\")\n",
        "        with open(fr_dev_p4_out_path, \"w+\", encoding=\"utf-8\") as file:\n",
        "            for line in predicted_results:\n",
        "                file.write(line + \"\\n\")\n",
        "\n",
        "\n",
        "labels_list, labels, N = FR_labels_list, FR_labels, FR_N\n",
        "input_tuple_data = read_training_data(fr_train_path)\n",
        "labels_count = calculate_number_of_labels(input_tuple_data)\n",
        "\n",
        "\n",
        "write_prediction_output_to_file_part4(\"FR\")\n",
        "\n",
        "labels_list, labels, N = create_labels_array_dict(en_train_path)\n",
        "input_tuple_data = generate_data_tuple_list_with_start_end(en_train_path) # Note the function used.\n",
        "labels_count = calculate_number_of_labels(input_tuple_data)\n",
        "# labels_list, labels, N = create_labels_array_dict(en_train_path)\n",
        "# en_dev_out_storage = generate_data_tuple_list_with_start_end(en_dev_out_path)\n",
        "# en_dev_p2_out_storage = generate_data_tuple_list_with_start_end(en_dev_p2_out_path)\n",
        "\n",
        "write_prediction_output_to_file_part4(\"EN\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "#Entity in gold data: 238\n",
            "#Entity in prediction: 174\n",
            "\n",
            "#Correct Entity : 117\n",
            "Entity  precision: 0.6724\n",
            "Entity  recall: 0.4916\n",
            "Entity  F: 0.5680\n",
            "\n",
            "#Correct Sentiment : 81\n",
            "Sentiment  precision: 0.4655\n",
            "Sentiment  recall: 0.3403\n",
            "Sentiment  F: 0.3932\n",
            "\n",
            "#Entity in gold data: 802\n",
            "#Entity in prediction: 971\n",
            "\n",
            "#Correct Entity : 620\n",
            "Entity  precision: 0.6385\n",
            "Entity  recall: 0.7731\n",
            "Entity  F: 0.6994\n",
            "\n",
            "#Correct Sentiment : 534\n",
            "Sentiment  precision: 0.5499\n",
            "Sentiment  recall: 0.6658\n",
            "Sentiment  F: 0.6024\n"
          ]
        }
      ],
      "source": [
        "!python .\\dataset\\FR\\evalResult.py .\\dataset\\FR\\dev.out .\\dataset\\FR\\dev.p4.out\n",
        "\n",
        "!python .\\dataset\\EN\\evalResult.py .\\dataset\\EN\\dev.out .\\dataset\\EN\\dev.p4.out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def write_TEST_prediction_output_to_file_part4(language):\n",
        "\n",
        "    if language == \"EN\":\n",
        "        # Conduct training/supervised learning (M-Step)\n",
        "        labels_list, labels, N = create_labels_array_dict(en_train_path)\n",
        "        input_tuple_data = read_training_data(en_train_path)\n",
        "        labels_count = calculate_number_of_labels(input_tuple_data)\n",
        "        unique_words_list = get_all_unique_words(input_tuple_data)\n",
        "\n",
        "        dict_of_count_of_words_in_each_label, dict_of_total_count_unique_words = count_unique_words_for_each_label(input_tuple_data, labels_list)\n",
        "        dict_of_words_prob_in_each_label = probabilities_of_words_in_each_label(dict_of_count_of_words_in_each_label, dict_of_total_count_unique_words)\n",
        "        \n",
        "\n",
        "        # Execute testing/decoding (E-Step)\n",
        "        predicted_results = []\n",
        "        test_data = read_dev_in_data(en_test_in_path)\n",
        "\n",
        "        for token in test_data:\n",
        "            if token:\n",
        "                predicted_results.append(token + \" \" + predict_word_sentiment(token, dict_of_words_prob_in_each_label, labels_list, unique_words_list))\n",
        "            else:\n",
        "                predicted_results.append(\"\")\n",
        "        with open(en_test_out_path, \"w+\", encoding=\"utf-8\") as file:\n",
        "            for line in predicted_results:\n",
        "                file.write(line + \"\\n\")\n",
        "\n",
        "    elif language == \"FR\":\n",
        "        # Conduct training/supervised learning (M-Step)\n",
        "        labels_list, labels, N = FR_labels_list, FR_labels, FR_N\n",
        "        input_tuple_data = read_training_data(fr_train_path)\n",
        "        labels_count = calculate_number_of_labels(input_tuple_data)\n",
        "        unique_words_list = get_all_unique_words(input_tuple_data)\n",
        "\n",
        "\n",
        "        dict_of_count_of_words_in_each_label, dict_of_total_count_unique_words = count_unique_words_for_each_label(input_tuple_data, labels_list)\n",
        "        dict_of_words_prob_in_each_label = probabilities_of_words_in_each_label(dict_of_count_of_words_in_each_label, dict_of_total_count_unique_words)\n",
        "        \n",
        "\n",
        "        # Execute testing/decoding (E-Step)\n",
        "        predicted_results = []\n",
        "        test_data = read_dev_in_data(fr_test_in_path)\n",
        "\n",
        "        for token in test_data:\n",
        "            if token:\n",
        "                predicted_results.append(token + \" \" + predict_word_sentiment(token, dict_of_words_prob_in_each_label, labels_list, unique_words_list))\n",
        "            else:\n",
        "                predicted_results.append(\"\")\n",
        "        with open(fr_test_out_path, \"w+\", encoding=\"utf-8\") as file:\n",
        "            for line in predicted_results:\n",
        "                file.write(line + \"\\n\")\n",
        "\n",
        "\n",
        "labels_list, labels, N = FR_labels_list, FR_labels, FR_N\n",
        "input_tuple_data = read_training_data(fr_train_path)\n",
        "labels_count = calculate_number_of_labels(input_tuple_data)\n",
        "\n",
        "\n",
        "write_TEST_prediction_output_to_file_part4(\"FR\")\n",
        "\n",
        "labels_list, labels, N = create_labels_array_dict(en_train_path)\n",
        "input_tuple_data = generate_data_tuple_list_with_start_end(en_train_path) # Note the function used.\n",
        "labels_count = calculate_number_of_labels(input_tuple_data)\n",
        "# labels_list, labels, N = create_labels_array_dict(en_train_path)\n",
        "# en_dev_out_storage = generate_data_tuple_list_with_start_end(en_dev_out_path)\n",
        "# en_dev_p2_out_storage = generate_data_tuple_list_with_start_end(en_dev_p2_out_path)\n",
        "\n",
        "write_TEST_prediction_output_to_file_part4(\"EN\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
